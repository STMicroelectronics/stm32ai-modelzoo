general:
  project_name: aed_project
  model_path: ..\pretrained_models\yamnet\ST_pretrainedmodel_public_dataset\esc10\yamnet_256_64x96_tl\yamnet_256_64x96_tl.h5
  # Change to the path of the model you wish to evaluate
  logs_dir: logs
  saved_models_dir: saved_models
  global_seed: 120
  # If you use the seed indicated in the pretrained model config files,
  # you can guarantee that the validation and quantization sets are the same.
  gpu_memory_limit: 5
  display_figures: True 
  batch_size: 16 # This is used to batch the eval dataset

operation_mode: chain_eqeb #chain_tbqeb
#choices=['training' , 'evaluation', 'prediction', 'deployment', 'quantization', 'benchmarking',
#        'chain_tbqeb','chain_tqe',' chain_eqe','chain_qb','chain_eqeb','chain_qd ']

dataset:
  name: esc10
  class_names: ['dog', 'chainsaw', 'crackling_fire', 'helicopter', 'rain', 'crying_baby', 'clock_tick', 'sneezing', 'rooster', 'sea_waves']
  file_extension: '.wav'

  # Note : It is not strictly necessary to provide a quantization dataset, but not doing so 
  # can greatly reduce quantized model performance
  # Here, we're using 10% of the ESC10 dataset to quantize
  # And we're using 20% of the dataset to evaluate.
  # But you can provide a seperate test set or quantization set.
  # If you use the seed indicated in the pretrained model config files,
  # you can guarantee that the validation and quantization sets are the same.
  training_audio_path: ../datasets/ESC-50/audio 
  training_csv_path:   ../datasets/ESC-50/meta/esc50.csv 

  validation_audio_path: # Optional
  validation_csv_path: # Optional
  validation_split: 0.2  # Optional, default value is 0.2

  quantization_audio_path: # Optional
  quantization_csv_path: # Optional
  quantization_split: 0.1 # Optional

  test_audio_path:  
  test_csv_path: 

  multi_label: False 
  use_garbage_class: False 
  n_samples_per_garbage_class: 2
  expand_last_dim: True
  seed: 120 # Optional, there is a default seed
  to_cache: True
  shuffle: True

preprocessing:
  min_length: 1
  max_length : 10
  target_rate: 16000
  top_db: 60
  frame_length: 3200
  hop_length: 3200
  trim_last_second: False
  lengthen : 'after'

feature_extraction:
  patch_length: 96
  n_mels: 64
  overlap: 0.25
  n_fft: 512
  hop_length: 160
  window_length: 400
  window: hann
  center: False
  pad_mode: constant
  power: 1.0
  fmin: 125
  fmax: 7500
  norm: None
  htk : True
  to_db : False
  include_last_patch: False

training:


quantization:
  quantizer: TFlite_converter
  quantization_type: PTQ
  quantization_input_type: int8
  quantization_output_type: float
  export_dir: quantized_models

tools:
  stedgeai:
    version: 9.1.0
    optimization: balanced
    on_cloud: True
    path_to_stedgeai: C:/Users/<XXXXX>/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/<*.*.*>/Utilities/windows/stedgeai.exe
  path_to_cubeIDE: C:/ST/STM32CubeIDE_1.15.0/STM32CubeIDE/stm32cubeide.exe

benchmarking:
  board: B-U585I-IOT02A

mlflow:
  uri: ./experiments_outputs/mlruns

hydra:
  run:
    dir: ./experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}