general:
  project_name: segmentation
  model_path: null
  saved_models_dir: saved_models
  gpu_memory_limit: 38
  global_seed: 127
  display_figures: false
  num_threads_tflite: 8
operation_mode: chain_tqe
dataset:
  name: pascal_voc
  class_names: ["background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus",
                "car", "cat", "chair", "cow", "dining table", "dog", "horse", "motorbike",
                "person", "potted plant", "sheep", "sofa", "train", "tv/monitor"]

  training_path: ../datasets/COCO2017_VOC2012/JPEGImages
  training_masks_path: ../datasets/COCO2017_VOC2012/SegmentationClassAug
  training_files_path: ../datasets/COCO2017_VOC2012/ImageSets/Segmentation/trainaug.txt

  validation_path: ../datasets/COCO2017_VOC2012/JPEGImages
  validation_masks_path: ../datasets/COCO2017_VOC2012/SegmentationClassAug
  validation_files_path: ../datasets/COCO2017_VOC2012/ImageSets/Segmentation/val.txt
  validation_split: 
  
  test_path: 
  test_masks_path: 
  test_files_path: 
  
  quantization_path: 
  quantization_masks_path:
  quantization_files_path:
  quantization_split: 0.2
preprocessing:
  rescaling:
    scale: 1/127.5
    offset: -1
  resizing:
    aspect_ratio: fit
    interpolation: bilinear
  color_mode: rgb
data_augmentation:
  random_contrast:
    factor: 0.4
    change_rate: 1.0
  random_gaussian_noise:
    stddev: (0.0001, 0.005)
  random_jpeg_quality:
    jpeg_quality: (60, 100)
    change_rate: 0.025
  random_posterize:
    bits: (4, 8)
    change_rate: 0.025
  random_brightness:
    factor: 0.05
    change_rate: 1.0
training:
  model:
    name: deeplab_v3
    output_stride: 16
    input_shape: (512, 512, 3)
    pretrained_weights: imagenet
    pretrained_model_path: null
  resume_training_from: null
  frozen_layers: None
  dropout: 0.6
  batch_size: 16
  epochs: 500
  optimizer:
    Adam:
      learning_rate: 0.005
  callbacks:
    ReduceLROnPlateau:
      monitor: val_accuracy
      mode: max
      factor: 0.5
      patience: 40
      min_lr: 1.0e-05
    EarlyStopping:
      monitor: val_accuracy
      mode: max
      restore_best_weights: true
      patience: 60
quantization:
  quantizer: TFlite_converter
  quantization_type: PTQ
  quantization_input_type: uint8
  quantization_output_type: float
  granularity: per_channel
  optimize: false
  export_dir: quantized_models
prediction:
  test_files_path: C:/ImageDatabases/VOC2012_test_nano/
benchmarking:
  board: STM32H747I-DISCO
tools:
   stedgeai:
      version: 9.1.0
      optimization: balanced
      on_cloud: True
      path_to_stedgeai: C:/Users/<XXXXX>/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/<*.*.*>/Utilities/windows/stedgeai.exe
   path_to_cubeIDE: C:/ST/STM32CubeIDE_1.15.0/STM32CubeIDE/stm32cubeide.exe
deployment:
  c_project_path: ../../stm32ai_application_code/semantic_segmentation/
  IDE: GCC
  verbosity: 1
  hardware_setup:
    serie: STM32H7
    board: STM32H747I-DISCO
mlflow:
  uri: ./experiments_outputs/mlruns
