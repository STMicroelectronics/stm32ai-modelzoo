general:
  project_name: human_activity_recognition
  model_path:  #../pretrained_models/ign/ST_pretrainedmodel_custom_dataset/mobility_v1/ign_wl_24/ign_wl_24.h5
  logs_dir: logs
  saved_models_dir: saved_models
  display_figures: True
  global_seed: 123
  gpu_memory_limit: 4

operation_mode: chain_tb
#choices=['benchmarking', 'deployment', 'evaluation', 'training', 'chain_tb']

dataset:
  name: wisdm  # wisdm or mobility_v1
  class_names: [Jogging,Stationary,Stairs,Walking] #[Stationary,Walking,Jogging,Biking] for mobility_v1 #[Jogging,Stationary,Stairs,Walking] for WISDM 
  training_path: ../datasets/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.txt  # Mandatory for all but deployment, and benchmarking
  validation_path: # ../datasets/mobility_v1/train.pkl      # Optional
  validation_split: 0.2   # Optional, default value is 0.2
  test_path: 
  test_split: 0.25      # Optional, default value is 0.25
  seed: 123               # Optional, there is a default seed

preprocessing:
  gravity_rot_sup: True
  normalization: False

training:
  model:    # Use it if you want to use a model from the zoo, mutually exclusive with 'general.model_path'
    name: ign
    input_shape: (24, 3, 1)
    pretrained_model_path:         # Optional, available for transfer learning with cnn models
  resume_training_from: # Optional, use to resume a training from a previous experiment.
                        # Example: experiments_outputs/YYYY_MM_DD_HH_mm_ss/saved_models/last_augmented_model.h5 
  # frozen_layers: (0:-1)            # Optional, use if you want to freeze some layers (by default all layers are trainable)
  dropout: 0.5                     # Optional, only used for `ign` or `gmp` model use it if you want a dropout layer to be included in the model
  batch_size: 256
  epochs: 200
  optimizer:
    Adam:
      learning_rate: 0.001
  callbacks:          # Optional section
    ReduceLROnPlateau:
      monitor: val_accuracy
      mode: max
      factor: 0.5
      patience: 40
      min_lr: 1.0e-05
    # LRWarmupCosineDecay:
    #   initial_lr: 0.0001
    #   warmup_steps: 100
    #   max_lr: 0.005
    #   hold_steps: 100
    #   decay_steps: 800
    #   end_lr: 5.0e-05
    EarlyStopping:
      monitor: val_accuracy
      mode: max
      restore_best_weights: true
      patience: 60
#  trained_model_path: trained.h5   # Optional, use it if you want to save the best model at the end of the training to a path of your choice

tools:
  stm32ai:
    version: 8.1.0
    optimization: balanced
    on_cloud: True
    path_to_stm32ai: C:/Users/XXX/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/8.1.0/Utilities/windows/stm32ai.exe
  path_to_cubeIDE: C:/ST/STM32CubeIDE_1.1.0/STM32CubeIDE/stm32cubeide.exe

benchmarking:
  board: B-U585I-IOT02A

deployment:
  c_project_path: ../../stm32ai_application_code/sensing_thread_x/
  IDE: GCC
  verbosity: 1
  hardware_setup:
    serie: STM32U5
    board: B-U585I-IOT02A

mlflow:
  uri: ./experiments_outputs/mlruns

hydra:
  run:
    dir: ./experiments_outputs/${now:%Y_%m_%d_%H_%M_%S}
